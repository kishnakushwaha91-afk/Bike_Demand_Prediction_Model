{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "24908239",
            "metadata": {},
            "source": [
                "# Bike Demand Prediction Model\n",
                "### Assignment Solution (IIT Madras â€“ Kaatru)\n",
                "\n",
                "## Goal\n",
                "Develop a model to find significant variables in predicting the demand for shared bikes.\n",
                "\n",
                "## key Improvements in this Version\n",
                "- **Data Preprocessing**: Handling categorical variables using One-Hot Encoding.\n",
                "- **Assumption Checking**: Checking Multicollinearity using VIF.\n",
                "- **Validation**: Using Train-Test Split to evaluate performance on unseen data.\n",
                "- **Residual Analysis**: Verifying the assumptions of Linear Regression."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d91ba09d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import statsmodels.api as sm\n",
                "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a18ca697",
            "metadata": {},
            "source": [
                "## 1. Load and Inspect Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b02c5265",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('day.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "130c94ec",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e31aa085",
            "metadata": {},
            "source": [
                "## 2. Data Cleaning & Feature Engineering\n",
                "We drop variables that are not useful for prediction or cause leakage:\n",
                "- `instant`: Index column.\n",
                "- `dteday`: Date is redundant as we have year, month, etc.\n",
                "- `casual`, `registered`: Target leakage (cnt = casual + registered)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "245c886f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_model = df.drop(['instant', 'dteday', 'casual', 'registered'], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "86fff27d",
            "metadata": {},
            "source": [
                "### Categorical Encoding\n",
                "Variables like `season`, `weathersit`, `mnth`, and `weekday` are categorical but encoded as integers. We must One-Hot Encode them to avoid ordinality assumptions (e.g., Season 4 > Season 1 is false logic)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e8d68c5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define categorical columns\n",
                "cat_cols = ['season', 'weathersit', 'mnth', 'weekday']\n",
                "\n",
                "# Create dummy variables (drop_first=True to avoid dummy variable trap)\n",
                "df_model = pd.get_dummies(df_model, columns=cat_cols, drop_first=True, dtype=int)\n",
                "df_model.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c04bb960",
            "metadata": {},
            "source": [
                "## 3. Multicollinearity Check (VIF)\n",
                "High correlation between independent variables affects the p-values and interpretation. We check Variance Inflation Factor (VIF)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "05a72213",
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
                "X_numeric = df[numeric_cols]\n",
                "X_numeric = sm.add_constant(X_numeric)\n",
                "\n",
                "vif_data = pd.DataFrame()\n",
                "vif_data[\"feature\"] = X_numeric.columns\n",
                "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(len(X_numeric.columns))]\n",
                "vif_data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "852b2339",
            "metadata": {},
            "source": [
                "**Observation**: `temp` and `atemp` have extremely high VIF (~63), indicating they are duplicates in information. We will drop `atemp`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "77acca82",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_model = df_model.drop(['atemp'], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09a43c77",
            "metadata": {},
            "source": [
                "## 4. Train-Test Split\n",
                "Splitting data into 70% Training and 30% Testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d2332c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df_model.drop('cnt', axis=1)\n",
                "y = df_model['cnt']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
                "\n",
                "print(f\"Train size: {X_train.shape}\")\n",
                "print(f\"Test size: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c6dcab7",
            "metadata": {},
            "source": [
                "## 5. Model Building (OLS Regression)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e7d222b",
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_sm = sm.add_constant(X_train)\n",
                "X_test_sm = sm.add_constant(X_test)\n",
                "\n",
                "lr_model = sm.OLS(y_train, X_train_sm).fit()\n",
                "print(lr_model.summary())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "222243cb",
            "metadata": {},
            "source": [
                "## 6. Residual Analysis\n",
                "Validating assumptions: \n",
                "1. **Normality of Residuals**: Distribution of error terms should be normal.\n",
                "2. **Homoscedasticity**: No pattern in residuals vs fitted values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4b7765f",
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train_pred = lr_model.predict(X_train_sm)\n",
                "residuals = y_train - y_train_pred\n",
                "\n",
                "plt.figure(figsize=(10,5))\n",
                "sns.histplot(residuals, kde=True)\n",
                "plt.title('Distribution of Residuals (Normality Check)')\n",
                "plt.xlabel('Residuals')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9e6b2f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10,5))\n",
                "plt.scatter(y_train_pred, residuals)\n",
                "plt.axhline(y=0, color='r', linestyle='--')\n",
                "plt.title('Residuals vs Fitted Values (Homoscedasticity Check)')\n",
                "plt.xlabel('Fitted Values')\n",
                "plt.ylabel('Residuals')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c7883ac",
            "metadata": {},
            "source": [
                "## 7. Model Evaluation\n",
                "checking performance on Test Data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79cf0794",
            "metadata": {},
            "outputs": [],
            "source": [
                "y_test_pred = lr_model.predict(X_test_sm)\n",
                "\n",
                "r2_train = r2_score(y_train, y_train_pred)\n",
                "r2_test = r2_score(y_test, y_test_pred)\n",
                "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
                "\n",
                "print(f\"Train R-squared: {r2_train:.4f}\")\n",
                "print(f\"Test R-squared: {r2_test:.4f}\")\n",
                "print(f\"Test RMSE: {rmse_test:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "21d8ee50",
            "metadata": {},
            "source": [
                "## 8. Final Outcome: Significant Variables\n",
                "Listing variables that are statistically significant ($p < 0.05$)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f28c5b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "p_values = lr_model.pvalues\n",
                "sig_vars = p_values[p_values < 0.05].index.tolist()\n",
                "\n",
                "print(\"Significant Variables (p < 0.05):\")\n",
                "for var in sig_vars:\n",
                "    print(f\"- {var}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (ml_env)",
            "language": "python",
            "name": "ml_env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
